---
layout: post
category : lessons
tagline: "Jekyll intro"
tags : [hci, ml, workshop]
---
{% include JB/setup %}

## Overview

This is about eNTERFACE 2013. [eNTERFACE 2013](http://eventos.fct.unl.pt/enterface13) was the 9th International 
Summer Workshop on Multimodal Interfaces. It was held in Lisbon, Portugal from the 15th of July to August 9th, 2013. 
It brings roughly about 80 researchers for one whole month and is thus the largest workshop on multimodal interfaces.

I was part of project P7: [Laugh when you are winning](http://eventos.fct.unl.pt/sites/default/files/enterface13/files/p7_proposal.pdf). 
UCLIC's professor Harry Griffin was the project leader and the members of the project were mainly part of the 
ILHAIRE consortium.

Yu Ding and I were from CNRS paris and our task was to synthesize lip motion from laughter phonemes. 
The entire architecture behind this can be found in the project description. Here I will just talk about my experience! 

Quite a few things about this is worth mentioning.

This place, I mean the entire workshop comprised of researchers with enormous experience in their respective fields. 
It was a fascinating opportunity to learn from these guys. And most importantly work with them.

If you have any project specific questions, specifically related to the stuff I did feel free to mail me. I will be more than happy to answer whatever I can.

 

### What is the project all about?

So the project was about building an avatar(virtual agent) that would play the "Yes/No" game with two participants(Human participants!). 
Just in case you do not know what the "Yes/No" game is here is a brief description.
It involves answering questions that one participant asks another without uttering the exact words "Yes" or "No".
So if someone asks you "Do you like Megan Fox?", you cannot say "Yes" directly. Answers like "Obviously, certainly, most likely"
are fine but you cannot say "Yes" or "No".

